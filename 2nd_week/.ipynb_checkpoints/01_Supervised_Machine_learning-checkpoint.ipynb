{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profundización de Algoritmos Supervizados\n",
    "\n",
    "Los objetivos de esta sección son:\n",
    "\n",
    "a) Entender como un grupo de distintos algoritmos de aprendizaje supervisado aprenden a estimar sus parámetros a partir de los datos para hacer nuevas predicciones.\n",
    "\n",
    "b) Entender las fortalezas y debilidades de un metodo particular de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordatorio de términos importantes\n",
    "\n",
    "#### Elementos de un dataset para algotirmos de aprendizaje supervisado\n",
    "Usando como ejemplo el ya visto dataset de frutas, podemos reconocer los siguientes elementos:\n",
    "\n",
    "a) Feature representation (Representación de características): Esta sección comprende el reconocimiento de las características de cada fruta y su conversión en un lenguage que el algoritmo pueda reconocer y manejar (masa, ancho, altura, color -> número)\n",
    "\n",
    "b) Data instances/samples/examples (X): Se refiere a cada fila con datos, en donde cada fila representa una fruta con sus respectivas caracteristicas. Almacenaremos todas las caracteristicas de cada fruta (file) en la variable X\n",
    "\n",
    "c) Target value (y): Corresponde a la etiqueta (label) asociada a cada fruta. Cada fruta esta representada por un número unico al tipo de fruta. (Manzana = 1, Mandarina = 2, etc)\n",
    "\n",
    "Finalmente nuestro set de datos estará descrito a través de una matriz, conde la primera columna de la matriz está dada por la etiqueta de cada fruta (y) serguido por las características de cada fruta (X) en las siguientes columnas.\n",
    "\n",
    "#### Pasos a seguir usando el dataset para algotirmos de aprendizaje supervisado\n",
    "La estructura de como trabajar con un dataset en un algoritmo de  ML supervisado son:\n",
    "\n",
    "a) Entrenar y testear el dataset: Tomamos un pedazo del dataset original y lo usamos para entrenar el algoritmo (train) y reservamos el resto del dataset para corroborar la eficiencia del algoritmo (test). En general los porcentajes del dataset que se usan para entrenar y testear el algoritmo son 75% y 25% respectivamente.\n",
    "Podemos separar el data set con la funcion train_test_split que nos entrega 4 objetos: X_train, X_test, y_train, y_test.\n",
    "\n",
    "b) Crear el estimador. Este puede ser clasificador o regresor. Para el caso de las frutas usamos KNeighborsClassifier indicandole el número de vecinos (k) que queremos usar en el algoritmo.\n",
    "\n",
    "c) Entrenamos el estimador con método fit, indicandole cual es el data set que debe usar para entrenar: X_train, y_train. Una vez entrenado, el estimador está listo para ser usado. \n",
    "\n",
    "d) Evaluamos el estimador con el método score, para ver que tan preciso es su predicción. Para eso usamos el test dataset donde nos indica el número de frutas que fue correctamente predicho vs el numero total de frutas del test dataset.\n",
    "\n",
    "e) Finalmente podemos usar el estimador para realizar una predicción usanto el método predict.\n",
    "\n",
    "#### Tipos de algoritmos de aprendizaje supervisado\n",
    "Existen 2 tipos de algoritmos de aprendizaje supervisado: Clasificadores de Regresión. Ambos necesitan un set de datos para entrenar.  \n",
    "\n",
    "a) Clasificadores usan valores discretos: \n",
    "- valores binarios: 0 (clase negativa) o 1 (clase positiva)\n",
    "- Multi-class: nombres de frutas: 1 (manzana), 2 (naranja), etc\n",
    "- Multi-label: pagina web con multiples topicos. Asignamos a cada topico un valor de referencia entre 0.0 y 1.0\n",
    "\n",
    "b) Regresión usa valores continuos:\n",
    "- predecir los valores de venta de una casa (valores continuos) dado el número de piezas que tenga, o la ubicación, etc\n",
    "\n",
    "Más tarde usaremos 2 algoritmos de aprendizaje supervisado: K-nearest neighbor y linear model fit usando minimos cuadrados. Estos 2 algoritmos representan 2 enfoques complementarios en aprendizaje supervisado. El alg. K-nearest neighbor hace pocos supuestos sobre la estructura de los datos dando predicciones potencialmente precisas pero sensibles a pequeños cambios en el set de entrenamiento. Por otro lado los modelos lineales hacen fuertes supestos sobre la estructura de los datos, dando comoresultado predicciones estables, pero potencialmente inprecisas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar la relación entre la complejidad de un modelo con la capacidad de predicción de este (eficiencia), dependiendo de la eficiencia obtenida usando el training set o el test set.\n",
    "\n",
    "<img src=\"accuracy_vs_complexity.png\">\n",
    "\n",
    "Usando el training set: A medida que la complejidad aumenta, por ejemplo con el clasificador knn cuando k disminuye, la eficiencia del modelo aumenta.\n",
    "\n",
    "Usando el test set: Sin embargo, al usar el test set observamos que la eficiencia aumenta hasta un valor optimo, pero a medida que la complejidad del modelo es mayor la eficiencia vuelve a disminuir, haciendo que el modelo sobreajuste los valores del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting\n",
    "La habilidad para predecir correctamente de una forma prolongada un set de datos se llama generalizar. ¿Como sabemos que nuestro modelo generaliza correctamente? o en otras palabras, ¿cómo sabemos que el modelo predice bien un data set nuevo?\n",
    "\n",
    "Generalmente ML hace una suposición importante: Datos futuros trendrán las mismas propiedades que los datos usados para entrenar, es decir, los datos futuros para predecir tienen la misma distribución que los datos de entrenamiento. Por lo tanto, si la eficiencia en el entrenamiento fue alta, se espera que también lo sea para los datos futuros.\n",
    "Desafortunadamente esto no es efectivo en todos los casos debido a lo que se conoce como overfitting y underfitting (sobreajustar o ajuste pobre de los datos).\n",
    "- Modelos que son muy simples, que incluso no son muy eficientes durante el proceso de entrenamiento sufren de underfitting y no generalizan correctamente datos futuros. Por ejemplo, en la figura 1 izquierda estaríamos haciendo un ajuste pobre si escogemos un modelo lineal para predecir datos futuros. Dado que solo en la parte inicial de los datos podemos ver un comportamiento lineal, pero a escala global se comporta cuadráticamente, obtendríamos una baja eficiencia.\n",
    "\n",
    "- Modelos que son muy complejos para la cantidad de datos de entrenamiento disponible sufren de overfitting, haciendo poco probable que generalizen bien los datos nuevos. Es decir, no son capaces de visualizar patrones a escala global dada la escasez de datos iniciales. Por ejemplo, en la figura 1 derecha estaríamos sobreajustando los datos si incorporamos un modelo polinomial que necesita de más parametros, que uno cuadrático.\n",
    "\n",
    "<img src=\"under_overfitting.png\">\n",
    "\n",
    "Otro ejemplo de esto mismo podemos verlo en un ajuste donde tenemos 2 clases cuyas caracteristicas 1 y 2 se pueden representar a través del scatter plot de la figura adjunta.\n",
    "\n",
    "<img src=\"under_overfitting2.png\">\n",
    "\n",
    "Finalmente, estudiando el resultado del caso con k-nn classificador podemos ver que al ajustar el valor de k estamos ajustando los valores del modelo. Ahora, al reducir el valor de K lo que hacemos es aumentar el valor de la varianza en los límites de decisión, ya que solo se estan ajustando valores locales en los bordes. Por lo tanto al disminuir k aumentamos la posibilidad de overfitting en el modelo, dando paso a no ser capaz de predecir correctamente datos futuros.\n",
    "\n",
    "<img src=\"overfitting_with_knn.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
